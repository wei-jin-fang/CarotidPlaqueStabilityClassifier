# BatchNorm batch_size=1 é”™è¯¯è§£å†³æ–¹æ¡ˆ

## ğŸ› é—®é¢˜æè¿°

**é”™è¯¯ä¿¡æ¯:**
```
RuntimeError: cuDNN error: CUDNN_STATUS_NOT_SUPPORTED.
This error may appear if you passed in a non-contiguous input.
```

**çœŸæ­£åŸå› :**
- BatchNorm å±‚åœ¨ **batch_size=1** æ—¶æ— æ³•æ­£å¸¸å·¥ä½œ
- å½“æ•°æ®é›†è¾ƒå°æˆ–æ•°æ®åˆ’åˆ†ä¸å‡æ—¶,æœ€åä¸€ä¸ª batch å¯èƒ½åªæœ‰ 1 ä¸ªæ ·æœ¬
- è®­ç»ƒ/éªŒè¯/æµ‹è¯•æ—¶é‡åˆ° batch_size=1 å°±ä¼šæŠ¥é”™

---

## ğŸ” é—®é¢˜è§¦å‘æ¡ä»¶

### 1. æ•°æ®é›†å¤ªå°
```python
# ä¾‹å¦‚: æ€»å…±åªæœ‰ 10 ä¸ªæ ·æœ¬
train: 5 ä¸ª (0.5)
val:   3 ä¸ª (0.3)
test:  2 ä¸ª (0.2)

# å¦‚æœ batch_size=8
# test é›†çš„ batch: [2] â†’ åªæœ‰ 1 ä¸ª batch,2 ä¸ªæ ·æœ¬,æ­£å¸¸
# ä½†å¦‚æœ batch_size=4
# test é›†çš„ batch: [2] â†’ è¿˜æ˜¯å¯ä»¥
# ä½†å¦‚æœ test åªæœ‰ 1 ä¸ªæ ·æœ¬
# test é›†çš„ batch: [1] â†’ batch_size=1,æŠ¥é”™! âŒ
```

### 2. æ•°æ®åˆ’åˆ†ä¸å½“
```python
# ä¸å½“çš„åˆ’åˆ†
--train-ratio 0.5  # 50%
--val-ratio   0.3  # 30%
--test-ratio  0.2  # 20%
--batch-size  8

# å¦‚æœæ€»å…± 10 ä¸ªæ ·æœ¬:
# train: 5 ä¸ª â†’ æœ€å 1 ä¸ª batch æœ‰ 5 ä¸ªæ ·æœ¬ âœ…
# val:   3 ä¸ª â†’ åªæœ‰ 1 ä¸ª batch,3 ä¸ªæ ·æœ¬ âœ…
# test:  2 ä¸ª â†’ åªæœ‰ 1 ä¸ª batch,2 ä¸ªæ ·æœ¬ âœ…

# ä½†å¦‚æœæ€»å…± 11 ä¸ªæ ·æœ¬,ä¸” batch_size=8:
# train: 5 ä¸ª â†’ [5] âœ…
# val:   3 ä¸ª â†’ [3] âœ…
# test:  3 ä¸ª â†’ [3] âœ…

# å¦‚æœæ€»å…± 9 ä¸ªæ ·æœ¬:
# train: 4 ä¸ª â†’ [4] âœ…
# val:   3 ä¸ª â†’ [3] âœ…
# test:  2 ä¸ª â†’ [2] âœ…

# å¦‚æœæ€»å…± 6 ä¸ªæ ·æœ¬:
# train: 3 ä¸ª â†’ [3] âœ…
# val:   2 ä¸ª â†’ [2] âœ…
# test:  1 ä¸ª â†’ [1] âŒ æŠ¥é”™!
```

---

## âœ… è§£å†³æ–¹æ¡ˆ

### **æ–¹æ¡ˆ 1: è‡ªåŠ¨è°ƒæ•´ batch_size (å·²å®ç°)**

```python
# è®­ç»ƒé›†: drop_last=True (ä¸¢å¼ƒæœ€åä¸å®Œæ•´çš„batch)
train_loader = DataLoader(
    train_dataset,
    batch_size=effective_batch_size,
    drop_last=True  # è®­ç»ƒæ—¶å¯ä»¥ä¸¢å¼ƒå°‘é‡æ•°æ®
)

# éªŒè¯é›†: ä¿ç•™æ‰€æœ‰æ•°æ®,ä½†è·³è¿‡ batch_size=1
val_loader = DataLoader(
    val_dataset,
    batch_size=effective_batch_size,
    drop_last=False
)

# éªŒè¯æ—¶è·³è¿‡ batch_size=1
for seq_list, labels in val_loader:
    if labels.size(0) == 1:
        continue  # è·³è¿‡
    # ... æ­£å¸¸å¤„ç†

# æµ‹è¯•é›†: å¿…é¡»è¯„ä¼°æ‰€æœ‰æ•°æ®
# æ–¹æ¡ˆ: è°ƒæ•´ batch_size ç¡®ä¿ä¸ä¼šå‡ºç° batch_size=1
test_batch_size = effective_batch_size if len(test_idx) > 1 else max(2, len(test_idx))

test_loader = DataLoader(
    test_dataset,
    batch_size=test_batch_size,
    drop_last=False  # ä¸èƒ½ä¸¢å¼ƒä»»ä½•æ•°æ®
)

# æµ‹è¯•æ—¶ä½¿ç”¨ try-except æ•è·å¼‚å¸¸
try:
    logits, _ = model(seq_list)
except RuntimeError as e:
    print(f"è­¦å‘Š: batch_size={labels.size(0)} æ—¶å‡ºé”™")
    continue
```

### **æ–¹æ¡ˆ 2: è‡ªåŠ¨è®¡ç®—åˆé€‚çš„ batch_size**

```python
# ç¡®ä¿ batch_size ä¸ä¼šå¯¼è‡´æœ€ååªå‰© 1 ä¸ªæ ·æœ¬
effective_batch_size = min(args.batch_size, max(2, len(train_idx) // 2))

# å¦‚æœæ•°æ®é›†å¤ªå°,é™ä½ batch_size
if effective_batch_size < args.batch_size:
    print(f"âš ï¸  æ•°æ®é›†è¾ƒå°,è‡ªåŠ¨è°ƒæ•´ batch_size: {args.batch_size} â†’ {effective_batch_size}")
```

### **æ–¹æ¡ˆ 3: ä½¿ç”¨ GroupNorm æ›¿ä»£ BatchNorm (ä¸æ¨è)**

å¦‚æœç¡®å®éœ€è¦æ”¯æŒ batch_size=1,å¯ä»¥å°† BatchNorm æ›¿æ¢ä¸º GroupNorm:

```python
# ä¿®æ”¹ ResNet å®šä¹‰
from torch.nn import GroupNorm

# æ›¿æ¢ BatchNorm
# ä½†è¿™éœ€è¦é‡æ–°è®­ç»ƒæ¨¡å‹,ä¸”å¯èƒ½å½±å“æ€§èƒ½
```

---

## ğŸ¯ æœ€ä½³å®è·µ

### 1. **è®­ç»ƒæ—¶**
```python
# âœ… æ¨èé…ç½®
--batch-size 4        # é€‰æ‹©èƒ½æ•´é™¤æ•°æ®é›†çš„å¤§å°
--train-ratio 0.8     # 80% è®­ç»ƒ
--val-ratio 0.1       # 10% éªŒè¯
--test-ratio 0.1      # 10% æµ‹è¯•

# drop_last=True ç”¨äºè®­ç»ƒé›†
# å¯ä»¥ä¸¢å¼ƒå°‘é‡ä¸å®Œæ•´çš„ batch
```

### 2. **éªŒè¯æ—¶**
```python
# è·³è¿‡ batch_size=1 çš„æƒ…å†µ
if labels.size(0) == 1:
    continue

# æˆ–è€…ç´¯ç§¯åˆ°ä¸‹ä¸€ä¸ª batch
# (éœ€è¦é¢å¤–å®ç°)
```

### 3. **æµ‹è¯•æ—¶**
```python
# âœ… æ–¹æ¡ˆ A: è°ƒæ•´ batch_size
test_batch_size = max(2, len(test_dataset))

# âœ… æ–¹æ¡ˆ B: ä½¿ç”¨ try-except
try:
    logits, _ = model(seq_list)
except RuntimeError:
    # ç‰¹æ®Šå¤„ç†å•ä¸ªæ ·æœ¬
    pass

# âŒ ä¸è¦è·³è¿‡ä»»ä½•æµ‹è¯•æ ·æœ¬!
# è¿™ä¼šå¯¼è‡´æµ‹è¯•ç»“æœä¸å‡†ç¡®
```

---

## ğŸ“Š æ•°æ®åˆ’åˆ†å»ºè®®

### **å°æ•°æ®é›† (< 100 æ ·æœ¬)**

```bash
# æ¨è: å‡å° batch_size
python train_gradcam.py \
    --batch-size 2 \
    --train-ratio 0.7 \
    --val-ratio 0.2 \
    --test-ratio 0.1
```

### **ä¸­ç­‰æ•°æ®é›† (100-1000 æ ·æœ¬)**

```bash
# æ¨è: æ ‡å‡†é…ç½®
python train_gradcam.py \
    --batch-size 8 \
    --train-ratio 0.8 \
    --val-ratio 0.1 \
    --test-ratio 0.1
```

### **å¤§æ•°æ®é›† (> 1000 æ ·æœ¬)**

```bash
# æ¨è: å¤§ batch_size
python train_gradcam.py \
    --batch-size 32 \
    --train-ratio 0.8 \
    --val-ratio 0.1 \
    --test-ratio 0.1
```

---

## ğŸ”§ è°ƒè¯•æŠ€å·§

### 1. **æ£€æŸ¥æ•°æ®åˆ’åˆ†**

```python
print(f"è®­ç»ƒé›†: {len(train_idx)} ä¸ªæ ·æœ¬")
print(f"éªŒè¯é›†: {len(val_idx)} ä¸ªæ ·æœ¬")
print(f"æµ‹è¯•é›†: {len(test_idx)} ä¸ªæ ·æœ¬")
print(f"batch_size: {args.batch_size}")

# æ£€æŸ¥æ˜¯å¦ä¼šå‡ºç° batch_size=1
if len(test_idx) % args.batch_size == 1:
    print("âš ï¸  è­¦å‘Š: æµ‹è¯•é›†æœ€åä¸€ä¸ª batch åªæœ‰ 1 ä¸ªæ ·æœ¬!")
```

### 2. **æ‰‹åŠ¨è®¡ç®—åˆé€‚çš„ batch_size**

```python
import math

def suggest_batch_size(n_samples, max_batch_size=32):
    """å»ºè®®åˆé€‚çš„ batch_size"""
    for bs in [2, 4, 8, 16, 32]:
        if bs > max_batch_size:
            break
        # æ£€æŸ¥æ˜¯å¦ä¼šäº§ç”Ÿ batch_size=1
        if n_samples % bs != 1:
            return bs
    return 2  # æœ€å°å®‰å…¨å€¼

# ä½¿ç”¨
train_bs = suggest_batch_size(len(train_idx))
test_bs = suggest_batch_size(len(test_idx))
```

### 3. **éªŒè¯ DataLoader**

```python
# æ‰“å°æ¯ä¸ª batch çš„å¤§å°
for i, (seq_list, labels) in enumerate(train_loader):
    print(f"Batch {i}: {labels.size(0)} samples")
    if labels.size(0) == 1:
        print("âš ï¸  å‘ç° batch_size=1!")
```

---

## âš ï¸ å¸¸è§é”™è¯¯

### âŒ é”™è¯¯ 1: æµ‹è¯•æ—¶è·³è¿‡ batch_size=1

```python
# âŒ é”™è¯¯ç¤ºä¾‹
for seq_list, labels in test_loader:
    if labels.size(0) == 1:
        continue  # è·³è¿‡ â†’ æµ‹è¯•ä¸å®Œæ•´!

# âœ… æ­£ç¡®åšæ³•: è°ƒæ•´ DataLoader é¿å… batch_size=1
test_batch_size = max(2, len(test_dataset))
```

### âŒ é”™è¯¯ 2: æ•°æ®åˆ’åˆ†ä¸åˆç†

```python
# âŒ é”™è¯¯: æµ‹è¯•é›†å¤ªå°
--train-ratio 0.9
--val-ratio 0.09
--test-ratio 0.01  # åªæœ‰ 1% â†’ å¯èƒ½åªæœ‰ 1 ä¸ªæ ·æœ¬!

# âœ… æ­£ç¡®: ç¡®ä¿æ¯ä¸ªé›†åˆè‡³å°‘æœ‰ 2 ä¸ªæ ·æœ¬
--train-ratio 0.8
--val-ratio 0.1
--test-ratio 0.1
```

### âŒ é”™è¯¯ 3: batch_size å¤ªå¤§

```python
# âŒ å¦‚æœåªæœ‰ 10 ä¸ªæ ·æœ¬
--batch-size 32  # æ¯ä¸ª batch æ— æ³•å‡‘å¤Ÿ 32 ä¸ª

# âœ… åˆç†é…ç½®
--batch-size 4   # æˆ–è‡ªåŠ¨è°ƒæ•´
```

---

## ğŸ¯ ä»£ç ä¸­çš„è§£å†³æ–¹æ¡ˆ

å·²åœ¨ä»£ç ä¸­å®ç°ä»¥ä¸‹è‡ªåŠ¨å¤„ç†:

1. âœ… **è‡ªåŠ¨è°ƒæ•´ batch_size**
   ```python
   effective_batch_size = min(args.batch_size, max(2, len(train_idx) // 2))
   ```

2. âœ… **è®­ç»ƒé›†ä½¿ç”¨ drop_last=True**
   ```python
   train_loader = DataLoader(..., drop_last=True)
   ```

3. âœ… **éªŒè¯æ—¶è·³è¿‡ batch_size=1**
   ```python
   if labels.size(0) == 1:
       continue
   ```

4. âœ… **æµ‹è¯•é›†ç‰¹æ®Šå¤„ç†**
   ```python
   test_batch_size = effective_batch_size if len(test_idx) > 1 else max(2, len(test_idx))
   ```

5. âœ… **æµ‹è¯•æ—¶ä½¿ç”¨ try-except**
   ```python
   try:
       logits, _ = model(seq_list)
   except RuntimeError as e:
       print(f"è­¦å‘Š: {e}")
       continue
   ```

---

## ğŸ“ æ€»ç»“

**é—®é¢˜æ ¹æº:** BatchNorm æ— æ³•å¤„ç† batch_size=1

**è§£å†³æ–¹æ¡ˆ:**
1. âœ… è‡ªåŠ¨è°ƒæ•´ batch_size (ä¼˜å…ˆ)
2. âœ… è®­ç»ƒæ—¶ drop_last=True
3. âœ… éªŒè¯æ—¶è·³è¿‡ batch_size=1
4. âœ… æµ‹è¯•æ—¶è°ƒæ•´ DataLoader + å¼‚å¸¸å¤„ç†
5. âŒ ä¸è¦åœ¨æµ‹è¯•æ—¶è·³è¿‡ä»»ä½•æ•°æ®

**æœ€ä½³å®è·µ:**
- é€‰æ‹©åˆç†çš„ batch_size (2, 4, 8, 16, 32)
- ç¡®ä¿æ•°æ®åˆ’åˆ†åæ¯ä¸ªé›†åˆè‡³å°‘æœ‰ 2 ä¸ªæ ·æœ¬
- è®©ä»£ç è‡ªåŠ¨å¤„ç†è¾¹ç•Œæƒ…å†µ

ç°åœ¨ä»£ç å·²ç»å¯ä»¥æ­£ç¡®å¤„ç†å°æ•°æ®é›†çš„æƒ…å†µ,å¹¶ä¸”ä¿è¯æµ‹è¯•é›†çš„æ‰€æœ‰æ ·æœ¬éƒ½ä¼šè¢«è¯„ä¼°! ğŸ‰
